{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9fhnoiEgkoQ",
        "outputId": "cb17b764-3d3e-4eff-942c-b30ffa04147f"
      },
      "source": [
        "# import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clFMft0-g1YH"
      },
      "source": [
        "df = pd.read_excel('/content/Dataset (2).xlsx',index_col=None)\n",
        "\n",
        "# Removing the unnecessary columns.\n",
        "df = df[['Comment','polarity']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7pyNvQFzebO",
        "outputId": "714f4702-9ae6-4e05-b23c-b42e2091a0fe"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Comment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO1s6uMChW3R"
      },
      "source": [
        "df.isna().sum()\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Gw1JU-xPhi-O",
        "outputId": "b05e913c-c91c-4ae3-f254-e8f05ac4463b"
      },
      "source": [
        "df.dropna()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@ProFootballTalk Maybe we should stop keeping ...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So good I had to share! Check out all the item...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I‚Äôm New on Twitter do follow friends ‚ù§Ô∏èü•∫ #foll...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Your favourite daily newspaper just added even...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@imKayrapolat @tsss67 @PurelyFootball That's b...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17995</th>\n",
              "      <td>Call me old fashion but I want a simple weddin...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17996</th>\n",
              "      <td>Not to mention, we‚Äôre talking about a generati...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17997</th>\n",
              "      <td>Drove by the south Whitby covid test center to...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>@leahmcelrath Um... this is 10 year old techno...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17999</th>\n",
              "      <td>In an interview with RMC Sport in France, Kyli...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17950 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Comment  polarity\n",
              "0      @ProFootballTalk Maybe we should stop keeping ...       2.0\n",
              "1      So good I had to share! Check out all the item...       5.0\n",
              "2      I‚Äôm New on Twitter do follow friends ‚ù§Ô∏èü•∫ #foll...       3.0\n",
              "3      Your favourite daily newspaper just added even...       3.0\n",
              "4      @imKayrapolat @tsss67 @PurelyFootball That's b...       2.0\n",
              "...                                                  ...       ...\n",
              "17995  Call me old fashion but I want a simple weddin...       3.0\n",
              "17996  Not to mention, we‚Äôre talking about a generati...       3.0\n",
              "17997  Drove by the south Whitby covid test center to...       3.0\n",
              "17998  @leahmcelrath Um... this is 10 year old techno...       3.0\n",
              "17999  In an interview with RMC Sport in France, Kyli...       3.0\n",
              "\n",
              "[17950 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAHMwtHehq-r"
      },
      "source": [
        "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
        "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
        "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
        "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
        "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
        "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
        "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
        "## set containing all stopwords.\n",
        "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
        "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
        "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
        "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from', \n",
        "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
        "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
        "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
        "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
        "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',\n",
        "             's', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
        "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
        "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those', \n",
        "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
        "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
        "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
        "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
        "##Function to clean the data.\n",
        "def preprocess(textdata , wordLemm):\n",
        "    processedText = []\n",
        "    \n",
        "    # Defining regex patterns.\n",
        "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "    userPattern       = '@[^\\s]+'\n",
        "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
        "    sequencePattern   = r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern = r\"\\1\\1\"\n",
        "    \n",
        "    for tweet in textdata:\n",
        "        tweet = tweet.lower()\n",
        "        \n",
        "        # Replace all URls with 'URL'\n",
        "        tweet = re.sub(urlPattern,' URL',tweet)\n",
        "        # Replace all emojis.\n",
        "        for emoji in emojis.keys():\n",
        "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
        "        # Replace @USERNAME to 'USER'.\n",
        "        tweet = re.sub(userPattern,' USER', tweet)        \n",
        "        # Replace all non alphabets.\n",
        "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
        "        # Replace 3 or more consecutive letters by 2 letter.\n",
        "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
        "        \n",
        "        tweetwords = ''\n",
        "        for word in tweet.split():\n",
        "            if len(word)>1:\n",
        "                # Lemmatizing the word.\n",
        "                word = wordLemm.lemmatize(word)\n",
        "                tweetwords += (word+' ')\n",
        "            \n",
        "        processedText.append(tweetwords)\n",
        "        \n",
        "    return processedText\n",
        "\n",
        "text, sentiment = list(df['Comment']), list(df['polarity'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuonT2udh3pz"
      },
      "source": [
        "wordLemm = WordNetLemmatizer()\n",
        "processedtext = preprocess(text , wordLemm)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JlS9w7Limgo"
      },
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(processedtext , sentiment , train_size = 0.8 , test_size = 0.2 , random_state = 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfWdH-F8ir0n",
        "outputId": "4543fe2f-0e5f-47e6-a02e-c30e0c1ab351"
      },
      "source": [
        "pd.DataFrame(X_train , y_train).info"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                                      0\n",
              "3.0            USER USER USER USER USER USER USER URL \n",
              "3.0  alright everyone this look planned this wa tod...\n",
              "4.0                                USER super fashion \n",
              "3.0  USER USER USER USER USER USER USER lmfao what ...\n",
              "3.0  penalty or no penalty ex prem referee verdict ...\n",
              "..                                                 ...\n",
              "3.0  ex referee responds to claim mitigating circum...\n",
              "3.0  USER stick to hockey max once you figure that ...\n",
              "3.0     should be allowed to hunt bitch for sport tbh \n",
              "3.0  new shoe at mere fraction of the price bargain...\n",
              "3.0  USER yes know lot of people say that and it ac...\n",
              "\n",
              "[14360 rows x 1 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYXJd_Skixxn"
      },
      "source": [
        "#incode the object columns by Tfidf\n",
        "Incoder = TfidfVectorizer(ngram_range=(1,2), max_features=1000000)\n",
        "Incoder.fit(X_train)\n",
        "\n",
        "X_train = Incoder.transform(X_train)\n",
        "X_test  = Incoder.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chvFcpP6i29C"
      },
      "source": [
        "#Function to compare between my models to chose one\n",
        "def model_Evaluate(model):\n",
        "    \n",
        "    # Predict values for Test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print the evaluation metrics for the dataset.\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsKLB_gIi6GV",
        "outputId": "69220c63-c1c5-4ccf-9713-c2bd4ec7c77c"
      },
      "source": [
        "SVCmodel = LinearSVC()\n",
        "SVCmodel.fit(X_train, y_train)\n",
        "model_Evaluate(SVCmodel)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.17      0.27        42\n",
            "         2.0       0.59      0.26      0.36       199\n",
            "         3.0       0.83      0.94      0.88      2257\n",
            "         4.0       0.74      0.62      0.68       672\n",
            "         5.0       0.90      0.82      0.86       420\n",
            "\n",
            "    accuracy                           0.82      3590\n",
            "   macro avg       0.77      0.56      0.61      3590\n",
            "weighted avg       0.81      0.82      0.80      3590\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEswZgf4i-BY",
        "outputId": "a0c91392-84d3-4501-bdf3-9c916e7a62c9"
      },
      "source": [
        "LogisticModel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "LogisticModel.fit(X_train, y_train)\n",
        "model_Evaluate(LogisticModel)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.07      0.13        42\n",
            "         2.0       0.64      0.14      0.22       199\n",
            "         3.0       0.79      0.96      0.87      2257\n",
            "         4.0       0.74      0.51      0.60       672\n",
            "         5.0       0.95      0.73      0.83       420\n",
            "\n",
            "    accuracy                           0.79      3590\n",
            "   macro avg       0.82      0.48      0.53      3590\n",
            "weighted avg       0.79      0.79      0.77      3590\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67wcqiEbjNVS"
      },
      "source": [
        "#Logistic regression did better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N57sbGJDjRE-"
      },
      "source": [
        "# Saving the model and the incoder\n",
        "file = open('Sentiment-LR-model.pickle','wb')\n",
        "pickle.dump(LogisticModel, file)\n",
        "file.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DLypUAejbF4"
      },
      "source": [
        "file = open('Incoder-ngram-(1,2).pickle','wb')\n",
        "pickle.dump(Incoder, file)\n",
        "file.close()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58gBB8w1jfGr",
        "outputId": "28d07fa3-5e8e-40a1-f666-114efc988baa"
      },
      "source": [
        "predictions = LogisticModel.predict(X_test)\n",
        "\n",
        "output = pd.DataFrame({'text': X_test, 'sentiment': predictions})\n",
        "output.to_csv('my_submission.csv', index=False)\n",
        "print(\"Your submission was successfully saved!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission was successfully saved!\n"
          ]
        }
      ]
    }
  ]
}